{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Grundlagen der Optimierung und Gradient Descent\n",
    "<a href=\"https://de.wikipedia.org/wiki/Optimierung_(Mathematik)\" target=\"_blank\">Optimierung</a> begegnet uns nahezu überall in modernen Problemen und interessanten Fragestellungen. Wir werden uns in diesem Notebook mit den Grundlagen der Optimierung befassen und dann auch noch einen konkreten Optimierungs-Algorithmus kennen lernen: <a href=\"https://de.wikipedia.org/wiki/Gradientenverfahren\" target=\"_blank\">Gradient Descent</a>.\n",
    "\n",
    "## 5.1 Was ist Optimierung\n",
    "Bei einem Optimierungsproblem geht es grundsätzlich darum, eine bestimmte Größe oder Funktion von Input-Variablen entweder zu maximieren oder zu minimieren. Diese Größe heißt je nach Kontext z.B. \"Zielfunktion\", \"Kostenfunktion\", \"Fitnessfunktion\", etc. Gemeint ist damit aber einfach immer jene Funktion, die optimiert werden soll.\n",
    "\n",
    "Grundsätzlich kann es bei Optimierungsproblemen verschiedene Einschränkungen geben:\n",
    "\n",
    "* Die erlaubten Wertebereiche der Input-Variablen können eingeschränkt sein\n",
    "* Die Wertebereiche der Zielfunktion können eingeschränkt sein\n",
    "* Die Werte der Input-Variablen können durch eine sogenannte Nebenbedingung zusammenhängen\n",
    "* Der \"Anspruch\" der Optimierung kann eingeschränkt sein auf entweder _lokale_ oder _globale_ Optima, die man finden möchte.\n",
    "\n",
    "\n",
    "Sehen wir uns gleich ein __einfaches Beispiel__ an, dass zwei dieser Einschränkungen aufweist:\n",
    "\n",
    "Finde jene beiden verschiedenen <a href=\"https://de.wikipedia.org/wiki/Zahl\" target=\"_blank\">Zahlen</a> aus der Menge der natürlichen Zahlen bis 10, die folgendes leisten:\n",
    "\n",
    "* Die Summe der beiden Zahlen muss 10 ergeben\n",
    "* Das Produkt der beiden Zahlen soll maximal sein\n",
    "\n",
    "\n",
    "Die eine Einschränkung ist die <a href=\"https://de.wikipedia.org/wiki/Nebenbedingung\" target=\"_blank\">Nebenbedingung</a> der fixen Summe, die andere Einschränkung ist, dass wir es mit natürlichen Zahlen zu tun haben, also einer diskreten (bzw. letztlich auch endlichen) Menge von möglichen Input-Werten.\n",
    "\n",
    "Um dieses Problem zu lösen müssten wir eigentlich gar nicht programmieren, sondern nur nachdenken. Aber ich werde trotzdem das Notebook nutzen, um das Beispiel zu illustrieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# zunächst die Imports für diese Einheit\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import sympy as sp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gib alle natürlichen Zahlen von 1 bis 10 aus\n",
    "number_array = np.arange(1,11,1)\n",
    "print(\"Kanidaten:\", number_array)\n",
    "\n",
    "# leere Liste, wo alle Paare hineinsollen, die die Bedingungen erfüllen\n",
    "pair_list = []\n",
    "\n",
    "# nun gehen wir alle Kombinationen durch\n",
    "for number_1 in number_array:\n",
    "    \n",
    "    for number_2 in number_array:\n",
    "        \n",
    "        # überprüfe die Summenvoraussetzung und die Ungleichheit\n",
    "        if (number_1 + number_2 == 10) and (number_1 != number_2):\n",
    "            # das ist interessant, gib die Zahlen und das Produkt aus\n",
    "            print(number_1, \"mal\", number_2, \"ist\", number_1 * number_2)\n",
    "            \n",
    "            # hänge diese Outputs auch an die Liste an\n",
    "            pair_list.append([number_1, number_2, number_1 * number_2])\n",
    "        \n",
    "# verwandle die Liste in ein Array\n",
    "pair_array = np.array(pair_list)\n",
    "\n",
    "# zum Schluss, finde das Maximum in der Liste\n",
    "optimal_position = np.argmax(pair_array[:, -1])\n",
    "\n",
    "optimal_solution = pair_array[optimal_position]\n",
    "\n",
    "print(\"Die optimale Lösung:\", optimal_solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Varianten der Optimierung\n",
    "Hier haben wir also gesehen, wie man, mehr oder weniger mit der Hand und eine nach der anderen, alle Möglichkeiten durchspielt und am Schluss nachsieht, welche Möglichkeit optimal ist. So eine herangehensweise nennt man oft <a href=\"https://de.wikipedia.org/wiki/Brute-Force-Methode\" target=\"_blank\">\"brute-force\"</a> approach, denn mehr als Rechengewalt haben wir nicht verwendet. Insbesondere haben wir folgendes __nicht__ getan:\n",
    "\n",
    "* Eine Formel verwendet, um die Lösung direkt zu bestimmen\n",
    "* Einen iterativen <a href=\"https://de.wikipedia.org/wiki/Algorithmus\" target=\"_blank\">Algorithmus</a> verwendet, der von einem Startwert aus Schritt für Schritt immer bessere Lösungsvorschläge liefert\n",
    "* Die Werte der Input-Variablen eingeschränkt, als wir sie in die Loops geschickt haben\n",
    "* Aus möglichen Input-Werten per Zufallsprinzip <a href=\"https://theoreticalphysics.eu/monte-carlo-methoden-simulation-und-integration/\" target=\"_blank\">gesampelt</a>, um Rechenzeit zu sparen, aber gleichzeitig trotzdem einen repräsentativen Teil aller Möglichkeiten abzubilden\n",
    "\n",
    "\n",
    "Diese Dinge sind natürlich grundsätzlich gute Möglichkeiten, um ein Optimierungsproblem zu vereinfachen. Machmal sind sie allerdings sogar unerlässlich, um überhaupt Fortschritte erzielen zu können. Nehmen wir dazu nocheinmal das obige Beispiel zur Hand und stellen wir uns vor, aus 10 würde eine viel größere Zahl.\n",
    "\n",
    "Aus unserer <a href=\"https://de.wikipedia.org/wiki/Zeitkomplexit%C3%A4t\" target=\"_blank\">Zeit-Komplexitäts</a>-Analyse wissen wir noch, dass ein Programm mit zwei Loops bis $N$ zunächst einmal wie $N^2$ skalieren wird. Hier kommt dann noch etwas dazu, nämlich die Suche nach dem Maximum in der entstandenen Liste. Uns geht es hier allerdings nicht so sehr um diese Details, sondern zunächst einmal darum, dass wir (auch von den Primzahlen damals) schon wissen, dass man hier im Prinzip ganz ordentlich einsparen kann, wenn man z.B. die Loops gut einschränken kann.\n",
    "\n",
    "Wenn wir hier z.B. den inneren Loop nur bis zu 1 unter der aktuellen Zahl im äußeren Loop laufen lassen, dann können wir sogar die Hälfte der if-Abfrage weglassen (nämlich ob die beiden Zahlen gleich sind). Somit ändern wir den Code etwas ab zu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wo liegt die Grenze?\n",
    "n = 1000\n",
    "\n",
    "number_array = np.arange(1, n+1, 1)\n",
    "# print(\"Kanidaten:\", number_array)\n",
    "\n",
    "# leere Liste, wo alle Paare hineinsollen, die die Bedingungen erfüllen\n",
    "pair_list = []\n",
    "\n",
    "# nun gehen wir nur mehr die Hälfte aller Kombinationen durch\n",
    "for number_1 in number_array:\n",
    "    \n",
    "    # der Zweite Loop wird jetzt früher abgebrochen\n",
    "    for number_2 in number_array[:number_1-1]:\n",
    "        \n",
    "        # überprüfe die Summenvoraussetzung\n",
    "        if (number_1 + number_2 == n):\n",
    "            # das ist interessant, gib die Zahlen und das Produkt aus\n",
    "            # print(number_1, \"mal\", number_2, \"ist\", number_1 * number_2)\n",
    "            \n",
    "            # hänge diese Outputs auch an die Liste an\n",
    "            pair_list.append([number_1, number_2, number_1 * number_2])\n",
    "\n",
    "# verwandle die Liste in ein Array\n",
    "pair_array = np.array(pair_list)\n",
    "\n",
    "# zum Schluss, finde das Maximum in der Liste\n",
    "optimal_position = np.argmax(pair_array[:, -1])\n",
    "\n",
    "optimal_solution = pair_array[optimal_position]\n",
    "\n",
    "print(\"Die optimale Lösung:\", optimal_solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Optimierung mit kontinuierlichen Variablen\n",
    "Unsere ersten Optimierungserfahrungen in diesem Notebook haben wir also mit diskreten Variablen gemacht. Oft werden Sie allerdings mit <a href=\"https://de.wikipedia.org/wiki/Kontinuum_(Mathematik)\" target=\"_blank\">kontinuierlichen</a> Variablen (z.B. Koordinaten) zu tun haben. Daher wenden wir uns nun dieser Situation zu und befassen uns gleich auch noch mit einem konkreten iterativen Lösungsalgorithmus dafür.\n",
    "\n",
    "Zunächst sehen wir uns einmal so ein Problem konkret an __einem Beispiel__ an. Nehmen wir z.B. folgendes: \n",
    "\n",
    "Gegeben ist die Funktion $f(x, y) = (x - 1)^2 + (y-2)^2 + 1$. Für welche $(x, y)$ ist $f$ minimal?\n",
    "\n",
    "Dazu noch ein paar Anmerkungen: \n",
    "\n",
    "* Üblicherweise kann man für Optimierungsprobleme mit kontinuierlichen Variablen die Wertebereiche der Input-Variablen einfach als $\\mathbb{R}$ annehmen (oder $\\mathbb{R}$, eingeschränkt auf ein Intervall). \n",
    "* Man muss aufpassen, dass man zwischen _lokalen_ und _globalen_ Optima unterscheidet. Ein lokales Minimum kann man z.B. mit Methoden aus der <a href=\"https://de.wikipedia.org/wiki/Differentialrechnung\" target=\"_blank\">Differenzialrechung</a> finden. Das muss jedoch nicht unbedingt auch das globale Minimum sein.\n",
    "* Insbesondere bei der Einschränkung der Input-Werte auf Intervalle muss man von vornherein wissen, ob man (ggf. eher) nach globalen oder lokalen Optima sucht.\n",
    "\n",
    "\n",
    "In unserem Beispiel suchen wir nach beidem gleichzeitig, denn die beiden sind identisch. Das können wir allerdings nur sagen, weil wir wissen, wie die Funktion in etwa aussieht. Hier ist sie z.B. einmal geplottet:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definiere f\n",
    "def our_function(x, y):\n",
    "    # Beachte: Die Argumente können hier Arrays sein\n",
    "    return (x-1)**2 + (y-2)**2 + 1\n",
    "\n",
    "# definiere x-Werte\n",
    "x_vals = np.linspace(-1, 3, 50)\n",
    "\n",
    "# definiere y-Werte\n",
    "y_vals = np.linspace(0, 4, 50)\n",
    "\n",
    "# erzeuge x-y-Grid für 3D Plots\n",
    "X, Y = np.meshgrid(x_vals, y_vals)\n",
    "\n",
    "Z = our_function(X, Y)\n",
    "\n",
    "# neue Grafik\n",
    "fig = plt.figure()\n",
    "\n",
    "# 3D Achsen erzeugen\n",
    "ax = fig.add_subplot(1,1,1, projection='3d')\n",
    "\n",
    "# erzeuge 3D-Oberflächenplot\n",
    "ax.plot_surface(X, Y, Z, cmap=\"magma\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So sieht also die Funktion aus. Es gibt auch noch andere Arten, so etwas zu plotten, z.B. diese:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neue Grafik\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "# 3D Achsen 1 erzeugen\n",
    "ax1 = fig.add_subplot(1,2,1, projection='3d')\n",
    "\n",
    "# erzeuge 3D-Oberflächenplot\n",
    "ax1.scatter(X, Y, Z, s=0.1)\n",
    "\n",
    "# 2D Achsen 2 erzeugen\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "\n",
    "# erzeuge 2D-Contourplot\n",
    "ax2.contour(X, Y, Z, 50, cmap='magma')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie kann man nun von so einer Funktion das Minimum finden? Beim <a href=\"https://theoreticalphysics.eu/vektoren-matrizen-und-vektorisierung-in-python/\" target=\"_blank\">Kapitel über Vektoren und Matrizen</a> hatten wir schon einmal so etwas ähnliches, nämlich über die <a href=\"https://de.wikipedia.org/wiki/Lineare_Regression\" target=\"_blank\">lineare Regression</a> (Zur besseren Erklärung: Dort war die Zielfunktion die Summe aller quadrierten Abstände der Beschreibung von den Datenpunkten). \n",
    "\n",
    "Wir haben damals die exakte Lösungsformel für den <a href=\"https://de.wikipedia.org/wiki/Methode_der_kleinsten_Quadrate\" target=\"_blank\">Least-Squares-Fit</a> aufgeschrieben und auch umgesetzt. Das ginge konkret auch bei dieser Form der Funktion (weil sie auch quadratisch ist), aber das geht nicht immer. Konkret muss man sogar sagen, dass sehr viele Optimierungsprobleme bisher keine Lösung in dem Sinn haben, dass kein Algorithmus bekannt ist, der das echte Optimum findet.\n",
    "\n",
    "Nichtsdestotrotz sind viele dieser Probleme zumindest _näherungsweise_ lösbar, und das ist meist gut genug. Wir werden uns daher hier einem Algorithmus zuwenden, der allgemein einsetzbar ist, und der zumindest näherungsweise Lösungen finden kann.\n",
    "\n",
    "## 5.4 Gradient Descent\n",
    "\n",
    "Beim Gradient-Descent-Algorithmus geht es darum, bei einer Minimierungsaufgabe dem Gradienten der (Hyper-)Fläche der Zielfunktion im Raum der Variablen Schritt für Schritt so zu folgen, dass man \"immer bergab\" geht. Stellen Sie sich vor, Sie stehen an einer riesigen Grube (z.B. einem Meteoritenkrater) und wollen an den tiefsten Punkt kommen. Dann könnten Sie folgendes tun:\n",
    "\n",
    "* Suchen Sie rund um Ihre Position herum jene Stelle, wo es am meisten bergab geht\n",
    "* Gibt es überhaupt eine Richtung, in der es bergab geht?\n",
    "  * Ja? Machen Sie einen Schritt in diese Richtung\n",
    "  * Nein? Sie haben ein (lokales) Minimum erreicht\n",
    "\n",
    "\n",
    "Mathematisch ausgedrückt macht man bei dieser Vorgehensweise folgendes:\n",
    "\n",
    "* Wählen Sie einen Startpunkt $(x_0, y_0)$\n",
    "* Wählen Sie eine Schrittweite $a$\n",
    "* Berechnen Sie dort den Gradienten $\\nabla f(x, y)|_{(x=x_0, y=y_0)}$\n",
    "* Berechnen Sie den nächsten Punkt, einen Schritt vom vorigen Punkt entfert, entlang des negativen Gradienten, also\n",
    "$$(x_1, y_1) = (x_0, y_0) - a \\nabla f(x, y)|_{(x=x_0, y=y_0)}$$\n",
    "* Nutzen Sie jetzt $(x_1, y_1)$ als neuen Startpunkt für den nächsten Schritt und wiederholen Sie das, bis die Abbruchbedingung erfüllt ist\n",
    "* Abbruchbedingung: Eine vorgegebene maximale Anzahl von Schritten oder irgendwann ist $||(x_n, y_n)-(x_{n-1}, y_{n-1})||<\\varepsilon$ für eine vorgegebene Genauigkeit $\\varepsilon$.\n",
    "\n",
    "\n",
    "Wir wollen nun diesen Algorithmus für unser obiges konkretes Beispiel durchgehen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definiere zwei Variablen x und y über SymPy\n",
    "x, y = sp.symbols('x, y')\n",
    "\n",
    "# definiere die Funktion f\n",
    "f = (x-1)**2 + (y-2)**2 + 1\n",
    "\n",
    "# Startwert \n",
    "x0 = np.array([0.5, 1.])\n",
    "\n",
    "# übergebe an wachsendes Array für den Pfad\n",
    "xy = np.array([x0])\n",
    "\n",
    "# Schrittweite\n",
    "a = 0.1\n",
    "\n",
    "# Loop über Schritte (wir lassen hier den Genauigkeitscheck einfach mal weg)\n",
    "for ind in range(100):\n",
    "    \n",
    "    # hole den letzten Punkt aus der Punkteliste (Pfad)\n",
    "    present_point = xy[-1]\n",
    "    \n",
    "    # schreibe den momentanen Punkt heraus\n",
    "    print(present_point)\n",
    "\n",
    "    # berechne den Gradienten and dieser Stelle\n",
    "    gradi = np.array([sp.diff(f, x).subs(x, present_point[0]).subs(y, present_point[1]),\n",
    "                      sp.diff(f, y).subs(x, present_point[0]).subs(y, present_point[1])])\n",
    "    \n",
    "    # mache einen Gradient-Descent Schritt, also ziehe den Gradienten mal Schrittweite\n",
    "    # vom derzeitigen Punkt ab\n",
    "    # hänge dann das Resultat an das xy-Array an\n",
    "    xy = np.append(xy, np.reshape(present_point - a * gradi, (1, 2)), axis=0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sehen wir uns das an\n",
    "fig = plt.figure()\n",
    "\n",
    "# 2D Achsen 2 erzeugen\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "# erzeuge 3D-Oberflächenplot\n",
    "ax.contour(X, Y, Z, 50, cmap='magma')\n",
    "\n",
    "# erzeuge x und y Werte aus dem Pfad\n",
    "x_vals, y_vals = np.transpose(xy)\n",
    "\n",
    "# Plotte zusätzlich den Pfad\n",
    "ax.plot(x_vals, y_vals, \"rx-\", markersize=10)\n",
    "\n",
    "# Plot anzeigen\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Übungsaufgabe: Spielen Sie mit dem Gradient-Descent-Algorithmus und dem Plot\n",
    "Kopieren Sie nun einfach die relevanten Code-Schnipsel von oben und probieren Sie folgende Dinge aus:\n",
    "\n",
    "* Nehmen Sie eine andere Funktion $f(x, y)$ und probieren Sie aus, was passiert\n",
    "* Passen Sie auch die Wertebereiche für $x$ und $y$ entsprechend an, sodass Sie im Plot sehen, wo der Algorithmus hinläuft\n",
    "* Experimentieren Sie auch mit der Schrittgröße:\n",
    "  * Was passiert, wenn $a$ zu klein gewählt wird?\n",
    "  * Was passiert, wenn $a$ zu groß gewählt wird?\n",
    "* Finden Sie eine Funktion $f$, für die dieser Algorithmus nicht konvergiert?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definiere eine andere Funktion g\n",
    "g = sp.sin((x-1)**2 + (y-2)**2)**2\n",
    "\n",
    "# Startwert \n",
    "x0 = np.array([0.5, 0.7])\n",
    "\n",
    "# übergebe an wachsendes Array für den Pfad\n",
    "xy = np.array([x0])\n",
    "\n",
    "# Schrittweite\n",
    "a = 0.05\n",
    "\n",
    "# Loop über Schritte (wir lassen hier den Genauigkeitscheck einfach mal weg)\n",
    "for ind in range(20):\n",
    "    \n",
    "    # hole den letzten Punkt aus der Punkteliste (Pfad)\n",
    "    present_point = xy[-1]\n",
    "    \n",
    "    # schreibe den momentanen Punkt heraus\n",
    "    print(present_point)\n",
    "\n",
    "    # berechne den Gradienten and dieser Stelle\n",
    "    gradi = np.array([sp.diff(g, x).subs(x, present_point[0]).subs(y, present_point[1]),\n",
    "                      sp.diff(g, y).subs(x, present_point[0]).subs(y, present_point[1])])\n",
    "    \n",
    "    # mache einen Gradient-Descent Schritt, also ziehe den Gradienten mal Schrittweite\n",
    "    # vom derzeitigen Punkt ab\n",
    "    # hänge dann das Resultat an das xy-Array an\n",
    "    xy = np.append(xy, np.reshape(present_point - a * gradi, (1, 2)), axis=0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passe Plotbereiche an\n",
    "\n",
    "# definiere x-Werte\n",
    "x_vals = np.linspace(0, 2, 250)\n",
    "\n",
    "# definiere y-Werte\n",
    "y_vals = np.linspace(0, 3, 250)\n",
    "\n",
    "# erzeuge x-y-Grid für 3D Plots\n",
    "X, Y = np.meshgrid(x_vals, y_vals)\n",
    "\n",
    "# erzeuge Funktion für numerische Auswertung automatisch\n",
    "# sodass sie für den Plot übereinstimmt\n",
    "g_num = sp.lambdify([x, y], g)\n",
    "\n",
    "# erzeuge Z-Werte über die lambdifizierte Funktion g\n",
    "Z = g_num(X, Y)\n",
    "\n",
    "\n",
    "\n",
    "# sehen wir uns auch das an\n",
    "fig = plt.figure()\n",
    "\n",
    "# 2D Achsen 2 erzeugen\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "# erzeuge 3D-Oberflächenplot\n",
    "ax.contour(X, Y, Z, 50, cmap='magma')\n",
    "\n",
    "# erzeuge x und y Werte aus dem Pfad\n",
    "x_vals, y_vals = np.transpose(xy)\n",
    "\n",
    "# Plotte zusätzlich den Pfad\n",
    "ax.plot(x_vals, y_vals, \"rx-\", markersize=10)\n",
    "\n",
    "# Plot anzeigen\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
