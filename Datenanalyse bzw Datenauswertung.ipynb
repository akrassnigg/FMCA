{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Datenanalyse bzw. Datenauswertung\n",
    "In dieser Einheit werden wir uns mit den nötigsten Grundlagen der <a href=\"https://de.wikipedia.org/wiki/Datenanalyse\" target=\"_blank\">Datenanalyse</a> bzw. Datenauswertung befassen. Das bedeutet z.B., wie man Daten einliest, was man damit (nicht) machen sollte und was man sich alles von Daten erwarten darf und was nicht.\n",
    "## 4.1 Dateneinlesen und Selektieren mit Pandas\n",
    "In <a href=\"https://www.python.org/\" target=\"_blank\">Python</a> gibt es eine Package, <a href=\"https://pandas.pydata.org/\" target=\"_blank\">Pandas</a>, die speziell für den einfachen Umgang mit Daten gedacht ist, die in Tabellenform abgelegt sind. Z.B. kann man aus einem <a href=\"https://de.wikipedia.org/wiki/Tabellenkalkulation\" target=\"_blank\">Tabellenkalkulationsprogramm</a> ein Arbeitsblatt im csv-Format speichern. CSV steht für <a href=\"https://de.wikipedia.org/wiki/CSV_(Dateiformat)\" target=\"_blank\">Comma-Separated Values</a> und ist ein oft verwendeter Standard, mit dem Sie sicher zumindest ab und zu zu tun haben sollten.\n",
    "\n",
    "Wir werden hier nicht in die Tiefen von Pandas abtauchen (dafür reicht unsere Zeit nicht), aber ich möchte Ihnen ein paar der wichtigsten Schritte von einem CSV-File zu einem <a href=\"https://numpy.org\" target=\"_blank\">NumPy</a>-Array zeigen. Denn was man damit alles macht, daran werden wir weiterhin arbeiten.\n",
    "\n",
    "Zunächst die Imports für diese Einheit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Lade die Pandas-Package\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das zentrale Objekt in Pandas ist ein _Dataframe_, das im Prinzip Tabellen- bzw. auch Datenbank-Charakter hat. Sie können sich das vereinfacht so vorstellen, dass die Spalten in der Tabelle Namen haben und die Zeilen durchnummeriert sind (so wie in einer Tabellenkalkulation). Wir sehen uns das jetzt gleich einmal an einem Beispiel an.\n",
    "\n",
    "Ich habe hier für Sie zwei Datensätze von <a href=\"https://kaggle.com\" target=\"_blank\">kaggle.com</a> bereitgestellt. Kaggle ist eine Plattform für <a href=\"https://de.wikipedia.org/wiki/Maschinelles_Lernen\" target=\"_blank\">Machine-Learning</a> Wettbewerbe, und dadurch auch über die Zeit zu einem sehr interessanten Repository für Datensätze geworden (die Registrierung ist kostenlos, falls sich das jemand von Ihnen ansehen möchte).\n",
    "\n",
    "Zunächst nehmen wir einen Datensatz zur Hand, der zu _GeoLifeCLEF 2022_ gehört. Dabei geht es darum, anhand von Bildmaterial (mit dem wir uns diesmal allerdings nicht beschäftigen werden) vorherzusagen, welche Spezies von Tieren und Pflanzen an diesem Ort leben. Die Basis dafür ist ein Satz von Trainingsdaten, in denen Beobachtungen von Spezies mit geografischer Länge und Breite gesammelt sind. Diese Liste von Beobachtungen wollen wir einlesen und ein wenig auswerten.\n",
    "\n",
    "Quelle:\n",
    "<a href=\"https://www.kaggle.com/competitions/geolifeclef-2022-lifeclef-2022-fgvc9/data\" target=\"_blank\">https://www.kaggle.com/competitions/geolifeclef-2022-lifeclef-2022-fgvc9/data</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einlesen des csv-Files in ein Pandas-Dataframe\n",
    "df_all = pd.read_csv(os.path.join(\"data\",\"observations_us_train.csv\"), delimiter=\";\")\n",
    "\n",
    "# Anzeigen der ersten paar Zeilen des Dataframe bzw. der Tabelle.\n",
    "# Man sieht hier die Spalten-Titel und die Indizes der Zeilen\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wir werden nun einige Zeilen aus der Tabelle nehmen, \n",
    "# und zwar durch Einschränkung auf die species_id\n",
    "\n",
    "# zunächst definieren wir eine Liste solcher IDs\n",
    "species_sample = [200, 20, 440, 57, 42, 7346]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeuge Figur\n",
    "fig = plt.figure(figsize=(8, 10))\n",
    "\n",
    "# Loop über Species-ID mit Position in der Liste\n",
    "for ind_species, a_species in enumerate(species_sample):\n",
    "        \n",
    "    # hole aus dem Dataframe jene Zeilen, die die jeweilige species ID haben\n",
    "    df_data_species_sample = df_all[df_all['species_id'] == a_species]\n",
    "\n",
    "    # Erzeuge ein Array zur weiteren Verwendung in numpy\n",
    "    plot_array = np.transpose(df_data_species_sample[['latitude', 'longitude']].to_numpy())\n",
    "\n",
    "    # Erzeuge einen neuen Subplot für diese Spezies\n",
    "    ax = plt.subplot(3, 2, ind_species+1)\n",
    "\n",
    "    # Erzeuge den Plot dieser Beobachtungen bezüglich Länge und Breite\n",
    "    ax.scatter(plot_array[1], plot_array[0])\n",
    "    \n",
    "    # Labels für die Achsen\n",
    "    ax.set_xlabel(\"Longitude\")\n",
    "    ax.set_ylabel(\"Latitude\")\n",
    "    \n",
    "    # noch die Spezies-ID als Titel in den Subplot\n",
    "    plt.title(\"spezies \"+str(a_species))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das sieht noch nicht nach allzuviel aus. Daher plotten\n",
    "# wir jetzt mal alle Beobachtungen für alle Spezies auf einmal\n",
    "\n",
    "# Erzeuge Figur\n",
    "fig = plt.figure()\n",
    "\n",
    "# Nimm alle Daten in den Spalten 'latitude', 'longitude' und mache \n",
    "# daraus ein numpy-Array\n",
    "plot_array = np.transpose(df_all[['latitude', 'longitude']].to_numpy())\n",
    "\n",
    "# Und ein Scatterplot der Daten. Die point size (s) wird klein gemacht \n",
    "# für eine schönere Auflösung/Darstellung\n",
    "plt.scatter(plot_array[1], plot_array[0], s=.0001)\n",
    "\n",
    "# Achsenbeschriftungen\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "\n",
    "# und Plot-Titel\n",
    "plt.title(\"Alle Spezies\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Datenanalyse, erste Schritte\n",
    "Wir werden uns jetzt noch einen anderen Datensatz organisieren, um damit etwas von der üblichen Auswertung anzusehen. Es handelt sich dabei um Ort und Zeit sowie Magnitude der Erdbeben mit $M>5.5$ von 1965 bis 2016.\n",
    "\n",
    "Quelle:\n",
    "<a href=\"https://www.kaggle.com/datasets/usgs/earthquake-database\" target=\"_blank\">https://www.kaggle.com/datasets/usgs/earthquake-database</a>\n",
    "\n",
    "Sehen wir uns das einfach mal an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einlesen des csv-Files in ein Pandas-Dataframe\n",
    "df_eq_all = pd.read_csv(os.path.join(\"data\",\"earthquake_database.csv\"), delimiter=\",\")\n",
    "\n",
    "# Anzeigen der ersten paar Zeilen des Dataframe bzw. der Tabelle.\n",
    "# Man sieht hier die Spalten-Titel und die Indizes der Zeilen\n",
    "df_eq_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# außerdem kann man sich für ein Dataframe \n",
    "# auch ein paar Statistiken anzeigen lassen:\n",
    "df_eq_all.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir werden allerdings jetzt auf _NumPy_ umsteigen und damit ein paar Dinge auseinandernehmen. Dabei erzeugen wir durch Abfrage einfach einmal ein recht großes <a href=\"https://kaggle.com\" target=\"_blank\">NumPy-Array</a> mit im Prinzip all jenen Daten, die wir verwerten wollen. Danach folgt die Analyse einzelner Spalten oder auch verschiedener möglicher Zusammenhänge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# die Spalten, die uns interessieren:\n",
    "column_labels = ['Date', 'Time', 'Latitude', 'Longitude', 'Depth', 'Depth Error', \n",
    "                 'Magnitude', 'Magnitude Error', 'Horizontal Error', 'Root Mean Square']\n",
    "\n",
    "# Schränke Typ auf Erdbeben ein (es gibt nämlich auch nukleare Explosionen)\n",
    "df_eq_data = df_eq_all[df_eq_all['Type'] == \"Earthquake\"]\n",
    "\n",
    "# Erzeuge gesamt-Daten-Array\n",
    "eq_data = df_eq_data[column_labels].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Erzeuge Figur\n",
    "fig = plt.figure()\n",
    "\n",
    "# Nimm alle Daten in den Spalten 'latitude', 'longitude' und transponiere \n",
    "# wieder das numpy-Array fürs Plotten\n",
    "plot_array = np.transpose(eq_data[:, 2:4])\n",
    "\n",
    "# Und ein Scatterplot der Daten. Die point size (s) wird klein gemacht \n",
    "# für eine schönere Auflösung/Darstellung\n",
    "plt.scatter(plot_array[1], plot_array[0], s=.001)\n",
    "\n",
    "# Achsenbeschriftungen\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "\n",
    "# und Plot-Titel\n",
    "plt.title(\"Alle Beben\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versuchen wir das nochmal, in 3D\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# hole Daten, diesmal Länge, Breite, Tiefe\n",
    "[breiten, laengen, tiefen] = np.transpose(eq_data[:, 2:5].astype(float))\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1, projection='3d')\n",
    "\n",
    "# Und ein Scatterplot der Daten. Die point size (s) wird klein gemacht \n",
    "# für eine schönere Auflösung/Darstellung\n",
    "ax.scatter(laengen, breiten, tiefen, s=.001)\n",
    "\n",
    "# Achsenbeschriftungen\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "#plt.zlabel(\"Depth\")\n",
    "\n",
    "# und Plot-Titel\n",
    "plt.title(\"Alle Beben\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# und wie wäre es, diesen Plot so aussehen zu lassen, wie eine Erdkugel?\n",
    "\n",
    "r_earth = 6370  # in km\n",
    "\n",
    "x_values = (r_earth - tiefen*5) * np.cos(breiten/180*np.pi) * np.cos(laengen/180*np.pi)\n",
    "y_values = (r_earth - tiefen*5) * np.cos(breiten/180*np.pi) * np.sin(laengen/180*np.pi)\n",
    "z_values = (r_earth - tiefen*5) * np.sin(breiten/180*np.pi) \n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Und ein Scatterplot der Daten. Die point size (s) wird klein gemacht \n",
    "# für eine schönere Auflösung/Darstellung\n",
    "ax.scatter(x_values, y_values, z_values, s=.001)\n",
    "\n",
    "# und Plot-Titel\n",
    "plt.title(\"Alle Beben, Tiefe fünffach eingezeichnet\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Einfache statistische Auswertung\n",
    "Nachdem wir uns die Daten angesehen und ein Gefühl dafür entwickelt haben, möchten wir uns aber noch ein paar quantitative Eigenschaften ansehen. Z.B. wollen wir versuchen, <a href=\"https://de.wikipedia.org/wiki/Mittelwert\" target=\"_blank\">Mittelwerte</a> und <a href=\"https://de.wikipedia.org/wiki/Varianz_(Stochastik)\" target=\"_blank\">Standardabweichungen</a> etwas genauer unter die Lupe zu nehmen.\n",
    "\n",
    "Die Basis dafür ist wieder _NumPy_, mit dem Array, das wir schon oben gebaut haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# berechne zunächst die arithmetischen Mittelwerte. \n",
    "# Zur Erinnerung: Spalten ab 2 sind numerisch, gemittelt wird über die Zeilen\n",
    "np.mean(eq_data[:, 2:].astype(float), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier gibt es offenbar einige NaNs, d.h. \"not a number\". \n",
    "# NumPy hat dafür eine spezielle mean-Funktion, die NaNs auslässt\n",
    "the_means = np.nanmean(eq_data[:, 2:].astype(float), axis=0)\n",
    "the_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machen wir das gleiche auch noch für die Standardabweichungen\n",
    "the_stds = np.nanstd(eq_data[:, 2:].astype(float), axis=0)\n",
    "the_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jetzt können wir hübsch herausschreiben, was passiert:\n",
    "# Spalten-Überschriften mit den Mittelwerten und Standardabweichungen\n",
    "for an_index, a_label in enumerate(column_labels[2:]):\n",
    "    print(\"Mittelwert für\", a_label, \":\", round(the_means[an_index], 3), \"+-\", round(the_stds[an_index], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier sehen wir ein paar seltsame Dinge, z.B. große Fehlerbalken bei kleinen Mittelwerten. Das ist allerdings bei Länge und Breite kein Wunder (denn das sind ja recht beliebige Koordinaten). Bei der Tiefe ist es allerdings schon etwas interessanter. Am besten sehen wir uns die Verteilung ein paar dieser Größen im Detail an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Nimm die Tiefenwerte und erstelle ein Histogramm\n",
    "depth_values = eq_data[:, 4]\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Histogramm der Tiefenwerte\n",
    "plt.hist(depth_values, bins=100)\n",
    "\n",
    "# Achsenbeschriftungen\n",
    "plt.xlabel(\"Tiefe in km\")\n",
    "plt.ylabel(\"Anzahl Beben\")\n",
    "\n",
    "# Skaliere x und/oder y Achse um\n",
    "#plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nehme nun die Magnituden und erstelle ein Histogramm\n",
    "mag_values = eq_data[:, 6]\n",
    "\n",
    "# Berechne die Anzahl der Bins für das Histogramm so, dass\n",
    "# jede zehntel-Magnitude ein Bin wird\n",
    "num_bins = int((np.max(mag_values) - np.min(mag_values))*10)\n",
    "\n",
    "# Ausgabe zum Mitschauen\n",
    "print(\"num_bins: \", num_bins)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Histogramm der Magnituden\n",
    "plt.hist(mag_values, bins=num_bins)\n",
    "\n",
    "# Achsenbeschriftungen\n",
    "plt.xlabel(\"Magnitude\")\n",
    "plt.ylabel(\"Anzahl Beben\")\n",
    "\n",
    "# Skaliere x und/oder y Achse um\n",
    "#plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Etwas komplexere statistische Auswertung\n",
    "Um noch etwas mehr Erfahrungen mit den Daten zu sammeln, wollen wir noch eins überprüfen, nämlich, ob Teile der Daten korreliert sind. Z.B. könnte man sich fragen, ob die Tiefe eines Erdbebens mit der Magnitude zusammenhängt.\n",
    "\n",
    "Das wollen wir uns anhand des <a href=\"https://de.wikipedia.org/wiki/Korrelationskoeffizient\" target=\"_blank\">Pearson-Korrelations-Koeffizienten</a> ansehen. Dieser ist 1, wenn eine perfekte Korrelation vorliegt, -1 bei einer Antikorrelation, und 0 bedeutet, dass es keine Korrelation gibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(mag_values.astype(float), depth_values.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# was it mit Längen und Breiten?\n",
    "np.corrcoef(eq_data[:, 2].astype(float), eq_data[:, 3].astype(float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Übungsaufgabe: Beben einer bestimmten Region\n",
    "In dieser Übungsaufgabe wollen wir die Korrelation von Längen und Breiten einiger Erdbeben nochmal ansehen, und zwar eingeschränkt auf eine bestimmte Region. Machen Sie also folgendes: \n",
    "\n",
    "* Nehmen Sie aus dem Daten-Array oben die Zeilen heraus (und kopieren Sie diese in ein neues Array), wo Längen und die Breiten in folgenden Fenstern liegen:\n",
    "  * Länge zwischen 165 und 171 Grad\n",
    "  * Breite zwischen -10 und -24 Grad\n",
    "* Berechnen Sie für das neue Array die Mittelwerte und Standardabweichungen für Tiefe und Magnitude. Wie vergleichen diese sich mit den obigen Werten für alle Beben?\n",
    "* Berechnen Sie die Korrelation zwischen Länge und Breite für diesen Teil der Daten. Was können Sie feststellen?\n",
    "\n",
    "__Zusatzaufgabe (optional)__: Kopieren Sie die Grafische 3D-Darstellung von oben und erzeugen Sie diese für das eingeschränkte Datenset. Nehmen Sie hierbei die Magnitude zur Hand und färben Sie darüber die Punkte im Plot verschieden ein. Das geht, indem Sie ein Array von Farbcodes mit _c=colorarray_ im _scatter_ Befehl zusätzlich zu den Koordinaten übergeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zur Erinnerung\n",
    "column_labels = ['Date', 'Time', 'Latitude', 'Longitude', 'Depth', 'Depth Error', \n",
    "                 'Magnitude', 'Magnitude Error', 'Horizontal Error', 'Root Mean Square']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erzeuge leere Listen zum Anhängen von Werten\n",
    "# für Daten\n",
    "restricted_data = []\n",
    "\n",
    "# für Farben bezüglich der Magnitude\n",
    "color_strings = []\n",
    "\n",
    "# Loop über alle Daten, Spalten \"Latitude\" bis \"Magnitude\"\n",
    "for a_line in eq_data[:, 2:7]:\n",
    "    # Abfrage der Koordinatenbereiche\n",
    "    if (165 < a_line[1] < 171) and (-10 > a_line[0] > -24):\n",
    "        # hänge Zeile an die Liste der eingeschränkten Daten an\n",
    "        restricted_data.append(a_line.astype(float))\n",
    "        \n",
    "        # setze Farbwerte für 3 Bereiche in der Magnitude\n",
    "        if a_line[4] > 7.5:\n",
    "            color_strings.append(\"r\")\n",
    "        elif a_line[4] > 6.5:\n",
    "            color_strings.append(\"g\")\n",
    "        else:\n",
    "            color_strings.append(\"b\")\n",
    "\n",
    "# mache aus dem Ganzen wieder ein Array\n",
    "restricted_data = np.array(restricted_data)   \n",
    "\n",
    "# übergebe das transponierte Array in die 4 interessanten Listen\n",
    "[breiten, laengen, tiefen, _, magnituden] = np.transpose(restricted_data)\n",
    " \n",
    "# gib die Minima und Maxima der Magnituden aus, um zu wissen, \n",
    "# wo die Gruppen von Magnituden-Werten sind\n",
    "print(\"Max Magnitude: \", np.max(magnituden))\n",
    "print(\"Min Magnitude: \", np.min(magnituden))   \n",
    "\n",
    "# Mittelwerte und Standardabweichungen für reduzierte Daten\n",
    "print(\"Tiefe:\", round(np.mean(tiefen), 3), \"+-\", round(np.std(tiefen), 3))\n",
    "print(\"Magnitude:\", round(np.mean(magnituden), 3), \"+-\", round(np.std(magnituden), 3))\n",
    "\n",
    "# gib den Korrelations\n",
    "np.corrcoef(breiten, laengen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei der durchschnittlichen Tiefe sieht man das gleiche Muster: Dort gibt es immer noch eine große Standardabweichung im Vergleich zum Mittelwert.\n",
    "\n",
    "Die (Anti-)Korrelation zwischen Länge und Breite ist allerdings sehr hoch. Wenn Sie sich die fragliche Region ansehen, werden Sie feststellen, dass sich dort tatsächlich eine lineare Erdbebenzone befindet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier noch der Erdkugelplot für die eingeschränkten Daten\n",
    "\n",
    "# Erdradius, nochmal zur Sicherheit\n",
    "r_earth = 6370  # in km\n",
    "\n",
    "# Die Koordinaten werden neu berechnet, aus dem eingeschränkten Datenset,\n",
    "# und diesmal ohne Faktor bei den Tiefen\n",
    "x_values = (r_earth - tiefen) * np.cos(breiten/180*np.pi) * np.cos(laengen/180*np.pi)\n",
    "y_values = (r_earth - tiefen) * np.cos(breiten/180*np.pi) * np.sin(laengen/180*np.pi)\n",
    "z_values = (r_earth - tiefen) * np.sin(breiten/180*np.pi) \n",
    "\n",
    "# wieder die 3D-Figur\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Und ein Scatterplot der Daten. Die point size (s) machen wir\n",
    "# diesmal groß, damit man die Farb-Unterschiede besser sieht\n",
    "ax.scatter(x_values, y_values, z_values, s=1, c=color_strings)\n",
    "\n",
    "# und Plot-Titel\n",
    "plt.title(\"Eingeschränkte Beben, Tiefe realistisch\")\n",
    "\n",
    "# können Sie die roten und grünen Punkte entdecken?\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
