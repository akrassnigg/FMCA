{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 Supervised Machine Learning: Grundlagen\n",
    "In dieser Einheit beschäftigen wir uns mit den Grundlagen des Supervised <a href=\"https://de.wikipedia.org/wiki/Maschinelles_Lernen\" target=\"_blank\">Machine Learnings</a>. Der Begriff <a href=\"https://de.wikipedia.org/wiki/Maschinelles_Lernen#%C3%9Cberwachtes_Lernen\" target=\"_blank\">\"supervised\"</a> bedeutet in diesem Zusammenhang, dass es zu jedem Datenpunkt einen Wert gibt, der die für das Machine Learning interessante Eigenschaft des Datenpunkts bezeichnet.\n",
    "\n",
    "Das kann z.B. die Zuordnung zu einer Klasse (bei einem <a href=\"https://de.wikipedia.org/wiki/Klassifikationsverfahren\" target=\"_blank\">Klassifikationsproblem</a>) sein, oder ein numerischer Wert (bei einem <a href=\"https://de.wikipedia.org/wiki/Regressionsanalyse\" target=\"_blank\">Regressionsproblem</a>). Was auch immer es ist, der allgemeine Begriff dafür ist \"Label\". Man spricht daher beim supervised Machine Learning auch grundsätzlich von \"labeled data\", also annotierten Daten.\n",
    "\n",
    "Im Gegensatz zum unsupervised Learning, das wir <a href=\"https://theoreticalphysics.eu/unsupervised-machine-learning-clustering-von-daten/\" target=\"_blank\">in der vorangegangenen Einheit</a> behandelt und ausprobiert haben, gibt es hier also recht direkte Möglichkeiten, zu versuchen, dem eigenen Computerprogramm eine Vorhersagekraft für die Eigenschaften eines Datensatztes \"beizubringen\". Dieser Prozess wird daher recht treffend auch als \"Training\" bezeichnet. Wie das genau vor sich geht, das werden wir uns noch etwas detaillierter ansehen.\n",
    "\n",
    "Zunächst möchte ich Ihnen aber einfach einmal ein Beispiel für gelabelte Datensätze zeigen. Fangen wir gleich mit Daten für ein Klassifikationsproblem an. Zunächst aber noch die Imports für heute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt # für plotting, wie gewohnt\n",
    "\n",
    "import numpy as np              # für numerische Aktionen mit Arrays, wie gewohnt\n",
    "\n",
    "# hier die Funktionen für die verschiedenen Schritte des Supervised Learning:\n",
    "\n",
    "from sklearn.datasets import make_moons, make_circles # zur Erzeugung von Datensets\n",
    "\n",
    "from sklearn.model_selection import train_test_split   # Aufteilen der daten in Train und Test\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree  # für Decision Tree Klassifikations-Algorithmus\n",
    "\n",
    "from sklearn.metrics  import accuracy_score  # zum Einschätzen der Qualität der Vorhersage\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1 Vorbereitung der Daten und der Labels für Supervised Learning mit Hilfe von Scikit-Learn\n",
    "\n",
    "Zunächst müssen wir die Daten vorbereiten. Für viele Datensätze, die man z.B. auf <a href=\"https://kaggle.com\" target=\"_blank\">kaggle.com</a> finden kann, ist das zwar schon passiert, aber manchmal muss man da selbst noch etwas nachbessern. Das gilt vor allem dann, wenn man sich die Input-Daten (auch _features_ genannt) und die Labels selbst aussuchen möchte. Damit wir allerdings nicht allzuviel Zeit damit zubringen, gibt es dafür eine kleine Abkürzung.\n",
    "\n",
    "Wir werden hier einen Datensatz selbst erzeugen, und zwar bereits mit der Machine-Learning Package <a href=\"https://scikit-learn.org\" target=\"_blank\">Scikit-Learn</a> selbst. Dort gibt es eigene Funktionalität für die Erzeugung von Test-Datensätzen, die wir hier ausprobieren werden. Obwohl das sehr einfach geht und eigentlich \"blind\" verwendet werden kann, sehen wir uns genau an, wie die Daten zusammengesetzt und aufgebaut sind.\n",
    "\n",
    "Ein Datensatz besteht aus einer Liste von $2$ Teilen:\n",
    "\n",
    "* Den Inputs/Features, als <a href=\"https://numpy.org/doc/stable/reference/generated/numpy.array.html\" target=\"_blank\">NumPy-Array</a>, d.h. eine Matrix, in deren Zeilen die Input-Daten-Vektoren stehen\n",
    "* Den Labels als Array, allerdings nur als eindimensionales, weil dort für jeden Input-Vektor nur eine Zahl (die Klassen-ID) steht.\n",
    "\n",
    "Mit Scikit-Learn kann man verschieden \"geformte\" 2D-Punktwolken erzeugen und diese als Datensätze ausgeben lassen. Dazu verwenden wir Funktionen aus dem Modul <a href=\"https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets\" target=\"_blank\">_sklearn.datasets_</a>:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeuge einen mondförmigen Datensatz mit 2 Klassen (also 2 Mond-Punktwolken)\n",
    "# noise bedeutet, wie sehr die Monde \"zerstreut\" werden\n",
    "# der random_state sorgt wieder für Reproduzierbarkeit\n",
    "raw_data = make_moons(n_samples=500, noise=0.1, random_state=0)\n",
    "\n",
    "# Der Output hat zwei Teile, der erste sind die Inputs\n",
    "input_data = raw_data[0]\n",
    "\n",
    "# der zweite sind die Labels\n",
    "label_data = raw_data[1]\n",
    "\n",
    "# Sehen wir uns das kurz an\n",
    "# Die ertsen 10 Input-Daten\n",
    "print(\"Features:\\n\", input_data[:10])\n",
    "\n",
    "# Die Labels (und zwar alle 500)\n",
    "print(\"Labels:\\n\", label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sehen wir uns das am besten gleich mal als Plot an\n",
    "fig=plt.figure()\n",
    "\n",
    "# setzen wir das Skalenverhältnis von x und y auf 1\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(1)\n",
    "\n",
    "\n",
    "# Ein Scatterplot, wie wir ihn schon gewohnt sind, mit Farben nach Klassen\n",
    "plt.scatter(*np.transpose(input_data), c=label_data)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das sieht wirklich sehr schön mondförmig aus (mit dem anfänglichen Wert von _noise_ von $0.1$. Das \"Rauschen\" könnten wir allerdings auch etwas aufdrehen, z.B. auf $0.9$, dann sieht das so aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise ist diesmal auf 0.9 gesetzt\n",
    "raw_data = make_moons(n_samples=500, noise=0.9, random_state=0)\n",
    "\n",
    "# Der fertige Datensatz hat zwei Teile, der erste sind die Inputs\n",
    "input_data = raw_data[0]\n",
    "\n",
    "# der zweite sind die Labels\n",
    "label_data = raw_data[1]\n",
    "\n",
    "# sehen wir uns das am besten gleich mal als Plot an\n",
    "fig=plt.figure()\n",
    "\n",
    "# Achsen-Skalen-Ratio wieder auf 1 setzen\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(1)\n",
    "\n",
    "# Der gleiche Scatterplot, mit Farben nach Klassen\n",
    "plt.scatter(*np.transpose(input_data), c=label_data)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Von Monden ist hier nicht mehr so viel zu sehen, aber man kann sie noch erahnen (wenn man es weiß). Lassen wir mal für die folgenden Experimente mit den verschiedenen Classifiern den _noise_-Wert auf $0.9$, damit es etwas interessanter wird.\n",
    "\n",
    "## 10.2 Ausgewogenheit der Daten beim Supervised Learning\n",
    "\n",
    "Eine Sache ist jedoch noch wichtig zu erwähnen, bevor wir zum Training kommen. Und zwar handelt es sich dabei um die Ausgewogenheit des Datensatzes, was die Labels betrifft. Es ist grundsätzlich wichtig auf einen ausgewogenen (balanced) Datensatz zu achten, damit es nicht zu (teilweise brutalen) Artefakten bei Vorhersagen kommt.\n",
    "\n",
    "Als extremes Beispiel stellen Sie sich kurz einen anderen Datensatz vor, bei dem es $99$ Daten der einen Klasse und nur einen einzigen Datenpunkt aus der anderen Klasse gibt. Auf diesen Daten ein gutes Modell zu trainieren, ist sehr schwierig. Aber es ist außerdem noch genauso schwierig, ein gutes Modell von einem komplett einseitigen Modell zu unterscheiden, und das kommt so: \n",
    "\n",
    "Ein Modell, das immer nur die vorherrschende Klasse vorhersagt, liegt damit nämlich bereits zu $99$ Prozent richtig. Das ist eigentlich für jedes Machine-Learning-Problem eine beeindruckende Performance. Trotzdem ist das Modell eigentlich unbrauchbar, gerade dann, wenn es auf die seltenen Fälle (aus der wenig repräsentierten Klasse) ankommt, weil man z.B. die Ausnahmen gut vorhersagen will.\n",
    "\n",
    "Das Fazit dieses kurzen Ausflugs: Ein ausgewogener Datensatz ist sehr wichtig für erfolgreiches Training. Schauen wir kurz nach, wie ausgewogen unser Datensatz mit den Monden ist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sehen wir uns grafisch an, wie die Labels in diesem Datensatz verteilt sind\n",
    "fig = plt.figure()\n",
    "\n",
    "# Erzeuge ein Histogramm der Labels\n",
    "plt.hist(label_data, bins=[0, 1, 2], width=0.3)\n",
    "\n",
    "# setze die x-Werte auf die Klassen-Indizes fest\n",
    "plt.xticks([0, 1])\n",
    "\n",
    "# Titel und Achsenbeschriftungen\n",
    "plt.title(\"Moons Test Dataset\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "# Plot anzeigen\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Verteilung ist hier also schön ausgeglichen, so wie es sein soll, wir haben hier also unsere \"balanced data\". Damit haben wir jetzt was die Vorbereitung der Daten betrifft unsere Schuldigkeit getan und können damit den nächsten Schritte tun.\n",
    "\n",
    "## 10.2 Die wichtigsten Schritte beim Supervised Learning im Allgemeinen\n",
    "\n",
    "Das Prozedere beim Supervised Learning ist üblicherweise folgendermaßen:\n",
    "\n",
    "* Die Daten werden zunächst vorbereitet und überprüft (das haben wir gerade getan).\n",
    "* Dann werden die Daten in zwei (oder drei) Teile geteilt, nämlich in einen Trainings-Teil und einen Test-Teil (und einen Validierungsteil, damit man Hyper-Parameter tunen kann, dazu kommen wir in der nächsten Einheit).\n",
    "* Der Trainingsteil sollte üblicherweise größer sein als der Rest, z.B. $80$ - $10$ - $10$ Prozent oder $60$ - $20$ - $20$. Wir werden es uns hier einfach machen und $80$ zu $20$ Prozent aufteilen und auf ein separates Validierungsset verzichten.\n",
    "* Beim Aufteilen werden die Daten üblicherweise auch durchgemischt. Das führt dazu, dass nicht lauter gleiche Labels hintereinander kommen, sondern auch die Reihenfolge ausbalanciert ist (wichtig fürs Training).\n",
    "* Dann bekommt der Machine-Learning-Algorithmus die Trainingsdaten, um sie zu fitten. Das geschieht je nach <a href=\"https://de.wikipedia.org/wiki/Algorithmus\" target=\"_blank\">Algorithmus</a> auf verschiedene, geeignete Arten.\n",
    "* Anschließend wird das erhaltene Machine-Learning-Modell auf den Testdaten ausprobiert. Das bedeutet, man schickt die Testdaten durch das Modell und vergleicht die vorhergesagten Ergebnisse mit den tatsächlichen Labels der Daten. \n",
    "* Beim Testen erhält man einen Score, z.B. das Verhältnis von richtig vorhergesagten Datenpunkten zu falsch vorhergesagten.\n",
    "* Je besser dieser Score, desto besser. Allerdings sollte man jedenfalls besser sein als zufälliges Raten, was z.B. bei $2$ Klassen $50$ Prozent wäre.\n",
    "\n",
    "Für alle diese Dinge verwenden wir durchgängig die Package <a href=\"https://scikit-learn.org\" target=\"_blank\">Scikit-Learn</a>, aus der wir ja in der vergangenen Einheit auch bereits die Algorithmen für das Unsupervised Learning importiert hatten.\n",
    "\n",
    "## 10.3 Aufteilen der Daten in Trainingsdaten und Testdaten\n",
    "\n",
    "So, nun konkret zu den Schritten. Teilen wir zunächst die Daten auf. Das geht ganz einfach mit einer Funktion aus Scikit-Learn, nämlich:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üblicherweise werden Daten beim Supervised Learning als X und y bezeichnet\n",
    "# Ja, das X ist wirklich groß und das y ist wirklich klein geschrieben :)\n",
    "# Hier bekommen wir eine zufällige Aufteilung (shuffle bedeutet durchmischen)\n",
    "# Für reproduzierbare Aufteilung den random_state auf einen Integer setzen\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_data, label_data, test_size=0.2,\n",
    "                                                    random_state=None, shuffle=True)\n",
    "\n",
    "# hier der Anfang von X_train\n",
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# und die Labels dazu\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sehen wir uns die Verteilung der Punkte im Plot an\n",
    "fig=plt.figure(figsize=(15,8))\n",
    "\n",
    "# Subplot für die Trainingsdaten\n",
    "ax1 = plt.subplot(1,2,1)\n",
    "ax1.set_aspect(1)\n",
    "\n",
    "# Ein Scatterplot für die Trainingsdaten, mit Farben nach Klassen\n",
    "ax1.scatter(*np.transpose(X_train), c=y_train)\n",
    "\n",
    "ax1.set_title(\"Train\")\n",
    "\n",
    "# Subplot für die Testdaten\n",
    "ax2 = plt.subplot(1,2,2)\n",
    "ax2.set_aspect(1)\n",
    "\n",
    "# Ein Scatterplot für die Testdaten, mit Farben nach Klassen\n",
    "ax2.scatter(*np.transpose(X_test), c=y_test)\n",
    "\n",
    "ax2.set_title(\"Test\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Modell soll also anhand der Punkte (mit Labels) auf der linken Seite lernen und die Punkte auf der rechten Seite möglichst richtig klassifizieren können, ohne diese beim Training gesehen zu haben.\n",
    "\n",
    "## 10.4 Supervised Learning: Das Training am Beispiel Decision Tree\n",
    "\n",
    "Jetzt können wir unsere Daten bereits in ein Machine-Learning-Modell füttern. Als Beispiel eignen sich hier einige aus dem <a href=\"https://scikit-learn.org/stable/supervised_learning.html\" target=\"_blank\">Supervised-Learning-Fundus von Scikit-Learn</a>. Wir beginnen mit einem <a href=\"https://scikit-learn.org/stable/modules/tree.html\" target=\"_blank\">Decision Tree</a> (<a href=\"https://de.wikipedia.org/wiki/Entscheidungsbaum\" target=\"_blank\">Entscheidungsbaum</a>). Dabei geht es darum, aus den Werten einzelner Inputs bzw. features Entscheidungen abzuleiten, die dann zum richtigen Ergebnis führen (im Mittel auf den Trainingsdaten). Beispiele dafür in unserem Fall wären Statements wie\n",
    "\n",
    "* Wenn $x<-0.5$, dann ist das Klasse 0\n",
    "* Wenn $x>0.5$, dann ist das Klasse 1\n",
    "* Wenn $-0.5<x<0.5$ und $y>1$, dann ist das Klasse 0\n",
    "* usw.\n",
    "\n",
    "Jetzt aber zum konkreten Aufruf für das Training. In Scikit-Learn sind alle Algorithmen fix und fertig implementiert, sodass man sie im Prinzip nur starten muss. Dazu muss man meist eine Instanz einer Klasse erzeugen, die wir im Allgemeinen dann direkt als \"Modell\" bzw. _model_ bezeichnen, und dann dafür einen \"Fit\" aufrufen, womit das Training gemeint ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufruf der Klasseninstanz für den Decision Tree Hier könnte man auch noch\n",
    "# diverse Parameter einstellen, wir schenken uns das aber für den Moment einmal\n",
    "model = DecisionTreeClassifier()     \n",
    "\n",
    "# damit ist jetzt das Modell definiert, und wir können diese Instanz verwenden\n",
    "\n",
    "# Aufruf des Fits. Danach hat die Instanz die Ergebnisse des Trainings parat\n",
    "# Dieser Teil kann, je nach Komplexität der Daten und des Modells, eine Zeit lang dauern\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Als nächstes rufen wir die Vorhersage der Werte auf dem \n",
    "# Test-Teil des Datensatzes auf. Zur Erinnerung: Diese Daten hat\n",
    "# das Modell während des Trainings nicht gesehen\n",
    "y_prediction = model.predict(X_test)\n",
    " \n",
    "# Das Ergebnis ist einfach ein Vektor mit vorhergesagten Labels\n",
    "# Was sind z.B. die ersten 5 Predictions aus dem Test-Set?\n",
    "y_prediction[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Und wie vergleicht sich das mit den echten Labels auf dem Testset?\n",
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naja, das ist noch nicht sehr aussagekräftig.\n",
    "\n",
    "# Plotten wir nun das Test-Set zweimal, eimmal mit den echten Klassen gefärbt,\n",
    "# einmal mit den vorhergesagten\n",
    "fig=plt.figure(figsize=(15,8))\n",
    "\n",
    "# Subplot für die echten Test-Daten und Labels\n",
    "ax1 = plt.subplot(1,2,1)\n",
    "ax1.set_aspect(1)\n",
    "\n",
    "# Ein Scatterplot für die Testdaten, mit Farben nach echten Klassen\n",
    "ax1.scatter(*np.transpose(X_test), c=y_test)\n",
    "\n",
    "ax1.set_title(\"Actual\")\n",
    "\n",
    "# Subplot für die Testdaten mit vorhergesagten Labels\n",
    "ax2 = plt.subplot(1,2,2)\n",
    "ax2.set_aspect(1)\n",
    "\n",
    "# Ein Scatterplot für die Testdaten, mit Farben nach vorhergesagten Klassen\n",
    "ax2.scatter(*np.transpose(X_test), c=y_prediction)\n",
    "\n",
    "ax2.set_title(\"Prediction\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das ist im ersten Moment etwas schwer zu erkennen ...\n",
    "# wir könnten aber auch noch die Unterschiede markieren ...\n",
    "fig=plt.figure(figsize=(15,8))\n",
    "\n",
    "# definiere Farbenliste je nach übereinstimmenden Labels (oder unterschiedlichen)\n",
    "edge_colors = []\n",
    "\n",
    "# Loop über gezippte Arrays für echte und vorhergesagte Labels\n",
    "for test_point, pred_point in zip(y_test,y_prediction):\n",
    "    \n",
    "    # Überprüfe, ob die Labels sich unterscheiden\n",
    "    if test_point != pred_point:\n",
    "        \n",
    "        # Ja, unterscheiden sich, umrande den Punkt rot\n",
    "        edge_colors.append('r')\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # Nein, sind gleich, umrande den Punkt weiß (d.h. nicht)\n",
    "        edge_colors.append('w')\n",
    "\n",
    "\n",
    "# Subplot für echte Labels\n",
    "ax1 = plt.subplot(1,2,1)\n",
    "ax1.set_aspect(1)\n",
    "\n",
    "# Ein Scatterplot für die Testdaten, mit Farben nach echten Klassen und mit Rändern für Unterschiede\n",
    "ax1.scatter(*np.transpose(X_test), c=y_test, edgecolors=edge_colors)\n",
    "\n",
    "ax1.set_title(\"Actual\")\n",
    "\n",
    "# Subplot für vorhergesagte Labels\n",
    "ax2 = plt.subplot(1,2,2)\n",
    "ax2.set_aspect(1)\n",
    "\n",
    "# Ein Scatterplot für die Testdaten, mit Farben nach vorhergesagten Klassen und mit Rändern für Unterschiede\n",
    "ax2.scatter(*np.transpose(X_test), c=y_prediction, edgecolors=edge_colors)\n",
    "\n",
    "ax2.set_title(\"Prediction\")\n",
    "\n",
    "# die Unterschiede sollten jetzt besser zu erkennen sein\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.5 Supervised Learning: Überprüfen der Genauigkeit der Vorhersagen des Machine-Learning-Modells\n",
    "\n",
    "Als nächstes wollen wir nun wissen, wie gut unsere Vorhersagen quantitativ sind. Dazu vergleichen wir die Output-Labels des Modells mit den tatsächlichen Labels des Test-Sets. Dafür gibt es in Scikit-Learn mehrere sogenannte <a href=\"https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\" target=\"_blank\">_metrics_</a>, die wir ebenfalls einfach aufrufen können, z.B. <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score\" target=\"_blank\">_accuracy_</a>, das ist im Wesentlichen der Anteil der korrekten Vorhersagen an allen Vorhersagen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechne Metrik accuracy für die Qualität der Vorhersage\n",
    "accuracy_score(y_test, y_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ist das jetzt gut oder nicht? Erinnern wir uns, dass die Hälfte der Daten Klasse $0$ ist, die andere Hälfte Klasse $1$. Das bedeutet, dass ein rein zufälliges Raten zu $50$ Prozent Genauigkeit führen müsste. Checken wir das einmal kurz ganz einfach, indem wir zufällig gewählte Klassen-Indizes mit den Test-Labels vergleichen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechne die Metrik accuracy für eine Zufallsauswahl aus 0en und 1en\n",
    "accuracy_score(y_test, np.random.choice([0, 1], size=len(y_test), replace=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das ist tatsächlich in der Nähe von $50$ Prozent. Die Abweichung kommt daher, dass wir hier mit $100$ Testdaten arbeiten, und das vergleichsweise wenige sind, sodass eine solche Abweichung vorkommen kann. Dagegen kann man allerdings die Qualität des Decision Trees nicht von vornherein einschätzen. Vielleicht können wir den ja noch etwas besser machen.\n",
    "\n",
    "## 10.6 Verbessern eines Machine-Learning-Modells beim Supervised Learning durch Verändern der Parameter am Beispiel Decision Tree\n",
    "\n",
    "In der folgenden Zelle kommt ein Aufruf, der zu einem weiteren Modell, _model1_, führt. Dabei werden wir die Struktur eines Decision Trees intuitiv etwas besser kennen lernen. Ein solcher Baum hat eine oder mehrere Verzweigungen, die zu weiteren Verzweigungen (in einer bestimmten Anzahl von Ebenen) oder \"Blättern\" führen können. Alle diese Teile heißen auf englisch _nodes_.\n",
    "\n",
    "Man kann nun den Baum auf ein paar Arten einschränken, sodass z.B.:\n",
    "\n",
    "* Eine maximale Anzahl von Blättern erlaubt ist\n",
    "* Eine maximale Anzahl von Verzweigungs-Ebenen erlaubt ist\n",
    "\n",
    "Diese beiden Parameter werden wir nun bei der Erzeugung der Instanz mit übergeben und so unseren Baum einschränken. Keine Sorge, sie werden gleich sehen, was das bedeutet und wie sich der Baum verändert, denn wir können ihn mit Hilfe einer __plot_tree__ Funktion auch gleich visualisieren.\n",
    "\n",
    "Grundsätzlich gilt, dass ein Baum nicht mehr Blätter haben kann, als seine Verzweigungen zulassen, die jeweils immer nur von einem _node_ in der höheren Ebene zu zwei _nodes_ in der darunter liegenden Ebene führen können. Bei Einer Ebene kann es also maximal zwei Blätter geben, bei zwei Ebenen vier Blätter, etc. Daher können wir die __max_leaf_nodes__ auf eine größere Zahl setzen, z.B. auf $10$, und dann wird die maximale Anzahl der Ebenen im Wesentlichen bestimmen, wie viele Nodes und Ebenen wie verwendet werden.\n",
    "\n",
    "Fangen wir mit einer Ebene an und gehen wir dann einfach mit dem Parameter __max_depth__ immer höher. Diese Zellen setze ich hier einfach mehrfach untereinander"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier also nochmal der Aufruf mit den beiden besprochenen Optionen, maximal eine Subebene\n",
    "model_1 = DecisionTreeClassifier(max_depth=1, max_leaf_nodes=10)\n",
    "\n",
    "# training des neuen Modells\n",
    "model_1.fit(X_train,y_train)\n",
    "\n",
    "# Vorhersage auf den Test-Daten\n",
    "y_prediction = model_1.predict(X_test)\n",
    "\n",
    "# und Genauigkeitsberechnung\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_prediction))\n",
    "\n",
    "# das Plotten funktioniert genau wie sonst auch bei Figures\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "# hier die Funktion für das Plotten des Baums\n",
    "plot_tree(model_1, fontsize=15)\n",
    "\n",
    "# und Anzeigen\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Relation in der ersten Zeile des Verzweigungsnodes ist die Bedingung, nach der die Datenpunkte aufgeteilt werden. Die Anzahl der aufgeteilten Punkte steht dann jeweils in den Nodes in der darunterliegenden Ebene. \"gini\" ist das Entscheidungskriterion, um eine optimale Bedingung zu finden. Konkret ist es ein Maß für die \"Unterschiedlichkeit\" in der Gruppe von Datenpunkten, sollte also idealerweise möglichst klein sein. Und im Array \"value\" finden sich die Anzahlen für die Klassenanteile der Daten in dieser Gruppe/diesem Node.\n",
    "\n",
    "Weiter geht es mit einer Subebene mehr:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# hier nochmal, diesmal mit 2 Subebenen\n",
    "model_1 = DecisionTreeClassifier(max_depth=2, max_leaf_nodes=10)\n",
    "\n",
    "# training des neuen Modells\n",
    "model_1.fit(X_train,y_train)\n",
    "\n",
    "# Vorhersage auf den Test-Daten\n",
    "y_prediction = model_1.predict(X_test)\n",
    "\n",
    "# und Genauigkeitsberechnung\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_prediction))\n",
    "\n",
    "# wieder plotten\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "# der gleiche Baum-Plotbefehl wie vorhin\n",
    "plot_tree(model_1, fontsize=15)\n",
    "\n",
    "# und Anzeigen\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# und nochmal, diesmal mit 3 Subebenen\n",
    "model_1 = DecisionTreeClassifier(max_depth=3, max_leaf_nodes=10)\n",
    "\n",
    "# training des neuen Modells\n",
    "model_1.fit(X_train,y_train)\n",
    "\n",
    "# Vorhersage auf den Test-Daten\n",
    "y_prediction = model_1.predict(X_test)\n",
    "\n",
    "# und Genauigkeitsberechnung\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_prediction))\n",
    "\n",
    "# wieder Plotten\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "# der Baum\n",
    "plot_tree(model_1, fontsize=15)\n",
    "\n",
    "# und Anzeigen\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# und noch ein letztes Mal, diesmal mit 4 Subebenen, dafür reichen \n",
    "# die 10 Blätter bereits nicht mehr ganz zum Ausfüllen aus\n",
    "model_1 = DecisionTreeClassifier(max_depth=4, max_leaf_nodes=10)\n",
    "\n",
    "# training des neuen Modells\n",
    "model_1.fit(X_train,y_train)\n",
    "\n",
    "# Vorhersage auf den Test-Daten\n",
    "y_prediction = model_1.predict(X_test)\n",
    "\n",
    "# und Genauigkeitsberechnung\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_prediction))\n",
    "\n",
    "# Plotten\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "# der Baum\n",
    "plot_tree(model_1, fontsize=15)\n",
    "\n",
    "# und Anzeigen\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier kann man sich sehr schön die Entwicklung der Bäume mit immer mehr Unter-Ebenen ansehen. Ebenso schön sieht man, wie der Baum versucht, die Datenpunkte möglichst gut und clever aufzuteilen, und wie manche der Blätter-Nodes sogar schon eine 0 auf einer Seite der \"values\" stehen haben. Was ist aber jetzt eigentlich mit der Genauigkeit insgesamt passiert? Sehen wir nach:\n",
    "\n",
    "Bereits bei der Einschränkung auf eine Ebene hatte sich der Wert der _accuracy_ etwas verschlechtert, und dann bei zwei Ebenen nochmal. Bei drei Ebenen und dann auch bei vier Ebenen ist der Wert der _accuracy_ allerdings wieder besser geworden, d.h., wie der Baum aussieht, spielt hier eine Rolle. Aber Achtung: Wie gut der Baum performt, kann von verschiedenen Dingen abhängen:\n",
    "\n",
    "* Von dem Datensatz, der untersucht wird\n",
    "* Von der Ausgeglichenheit des Datensatzes\n",
    "* Von der (zufälligen) Aufteilung in Training und Test\n",
    "\n",
    "Wenn sich davon etwas ändert, z.B. die Train-Test-Aufteilung, dann kann die Performance-Kurve für unsere Daten und für die gewählten Parameter durchaus anders aussehen und auch umgekehrte Trends aufweisen.\n",
    "\n",
    "Kommen wir aber nochmal zum Anfang zurück: Da wir dort (ohne Optionen im Aufruf) ja im Prinzip den besten Performance-Wert erhalten hatten, stellt sich die Frage:\n",
    "\n",
    "Was haben wir denn da dann ursprünglich eigentlich für einen Baum verwendet? Hier ist er:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nochmal Plotten \n",
    "fig = plt.figure(figsize=(15,10), dpi=150)\n",
    "\n",
    "# hier die Funktion für das Plotten des ersten Baums ohne jegliche Parameter\n",
    "# die Fontsize ist hier etwas kleiner gewählt, damit man die Boxen besser im Überblick sieht\n",
    "plot_tree(model, fontsize=4)\n",
    "\n",
    "# und Anzeigen\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insgesamt sieht man hier, dass Supervised Learning viel mit Verständnis der Situation, der Daten, des Modells, dessen Möglichkeiten und der Hintergründe zu tun hat. Insgesamt ist hier auf jeden Fall die eigene Erfahrung wesentlich, denn nur über solche Dinge nachzulesen hilft für viele Probleme nicht weiter.\n",
    "\n",
    "Damit Sie selbst gleich ein Bisschen Erfahrung sammeln können, kommen wir daher jetzt zur Übungsaufgabe dieser Einheit:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.7 Übungsaufgabe: Experimentieren mit Supervised-Learning Algorithmen aus der Scikit-Learn Package\n",
    "\n",
    "Nach dieser Einführung wissen Sie folgendes:\n",
    "\n",
    "* Wie ein Datensatz beim Supervised Learning strukturiert ist\n",
    "* Wie man einfache Datensätze zum Trainieren in Python mit Scikit-Learn erzeugen kann\n",
    "* Wie Supervised Learning grundsätzlich abläuft\n",
    "* Wie Sie einfache Modelle mit Scikit-Learn trainieren\n",
    "* Wie Sie mit einem trainierten Modell Vorhersagen machen\n",
    "* Wie Sie die Qualität einer Vorhersage auf einem Test-Set überprüfen\n",
    "* Wie Sie Ergebnisse und andere hilfreiche Informationen visualisieren können\n",
    "\n",
    "Diese Vorgehensweise ist immer die gleiche. In Scikit-Learn ist auch die grundsätzliche Code-Struktur immer gleich. Wenn Sie also eine Instanz eines Machine-Learning-Modells erzeugt haben, dann funktioniert das Training und die Vorhersagen immer gleich. Alles, was Sie austauschen müssen, sind die Modell-Aufrufe (und die eventuell damit verbundenen Parameter). \n",
    "\n",
    "Gehen Sie nun in der <a href=\"https://scikit-learn.org/stable/supervised_learning.html\" target=\"_blank\">Scikit-Learn-Übersicht für Supervised Learning</a> auf die Suche nach weiteren interessanten Algorithmen, die Sie gerne auf unseren Datensatz loslassen würden. Oder erzeugen Sie einen eigenen Datensatz nach Ihren Wünschen und experimentieren Sie damit. Ich wünsche viel Vergnügen!\n",
    "\n",
    "Hier schon mal ein paar Zeilen als Inspiration/Start, denn die Möglichkeiten sind sehr vielfältig und umfangreich (damit könnten wir mehrere zusätzliche Lehrveranstaltungen füllen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC   # für Support-Vector Machine\n",
    "from sklearn.naive_bayes import GaussianNB   # für Naive Bayes Classifier\n",
    "from sklearn.neighbors import NearestNeighbors   # für Nearest-Neighbor\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
